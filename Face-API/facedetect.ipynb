{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face import FaceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metodo para obtener credencial y cliente\n",
    "#COGNITIVE_SERVICE_KEY_1='611d04a1037e4bd0867aba781eccdcad'\n",
    "#COGNITIVE_SERVICE_ENDPOINT_1='https://bea-faceapi1.cognitiveservices.azure.com/''\n",
    "\n",
    "\n",
    "def get_face_client():\n",
    "    \"\"\"Create an authenticated FaceClient.\"\"\"\n",
    "    #SUBSCRIPTION_KEY = os.environ[\"COGNITIVE_SERVICE_KEY\"]\n",
    "    SUBSCRIPTION_KEY = 'xx'\n",
    "    #ENDPOINT = os.environ[\"COGNITIVE_SERVICE_ENDPOINT\"]\n",
    "    ENDPOINT = 'xx'\n",
    "    credential = CognitiveServicesCredentials(SUBSCRIPTION_KEY)\n",
    "    return FaceClient(ENDPOINT, credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'faceId': '12fec98c-53ef-4707-b10e-5b6d5f1d92f8', 'faceRectangle': {'top': 303, 'left': 920, 'width': 161, 'height': 161}, 'faceAttributes': {'smile': 0.978, 'glasses': 'ReadingGlasses', 'emotion': {'anger': 0.0, 'contempt': 0.0, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.978, 'neutral': 0.019, 'sadness': 0.002, 'surprise': 0.0}}}]\n"
     ]
    }
   ],
   "source": [
    "#DETECCION DE CARAS. imagen de la url\n",
    "face_client = get_face_client()\n",
    "\n",
    "url = \"https://docs.microsoft.com/en-us/learn/data-ai-cert/identify-faces-with-computer-vision/media/clo19_ubisoft_azure_068.png\"\n",
    "\n",
    "attributes = [\"emotion\", \"glasses\", \"smile\"]\n",
    "include_id = True\n",
    "include_landmarks = False\n",
    "\n",
    "detected_faces = face_client.face.detect_with_url(url, include_id, include_landmarks, attributes, raw=True)\n",
    "\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected in image')\n",
    "\n",
    " #si la imagen tiene una cara, el JSON salida es el siguiente con los siguientes elementos   \n",
    "print(detected_faces.response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
